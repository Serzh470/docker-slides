# Slide 3

Зачем нужны виртуальные машины

С помощью них можно эффективнее использовать физическое оборудование — значит, для решения поставленных задач его нужно
меньше. Также при использовании виртуальной машины снижается потребность в электроэнергии и охлаждении.

Кроме того, преимуществами виртуальных машин пользуются, чтобы упростить резервное копирование, аварийное восстановление
инфраструктуры, новые развертывания приложений и базовые задачи системного администрирования — новую ВМ с нужной ОС и кодом легко развернуть из виртуального образа.

Виртуальные машины легко перемещать между физическими серверами, например, когда надо заменить оборудование на новое или
перераспределить нагрузку между серверами. Это упрощает управление кластером, то есть группой из нескольких серверов.
Также ВМ можно копировать для оптимизации использования аппаратных ресурсов.

Разные виртуальные машины на одном физическом сервере обычно потребляют разное количество ресурсов, то есть одна из
них может использовать всё доступное физическое хранилище, а другая хранить мало файлов, поэтому требуется
балансировка распределения доступных ресурсов между ВМ.

  ## Варианты использования:

Например, когда компания хочет одновременно протестировать несколько веб-серверов и небольших баз данных.
Или хочет запустить на одном и том же оборудовании, например, игровой сервер с мощной графикой и базу данных для обслуживания клиентов.

Вот еще несколько вариантов использования виртуальных машин:

- защита информации и ограничение возможностей программ (песочница);
- исследование производительности программного обеспечения;
- эмуляция на оборудовании различных архитектур (например игровой приставки);
- оптимизация использования ресурсов физических серверов;
- тестирование и отладка системного программного обеспечения;

И вроде все Ок, решаются многие проблемы, но что-то все равно лишее...

# Slide 4

Контейнеры - это абстракция на уровне приложений, содержащая их код и зависимости.
Множество контейнеров могут быть запущены на одном ядре ОС вместе с остальными,
при этом каждый будет работать как изолированный процесс.

Эти контейнеры содержат код, системные инструменты, среду выполнения, системные библиотеки и параметры,
необходимые для запуска приложений. Их часто используют, когда требуется работа нескольких приложений на одной
и той же операционной системе. Контейнеры полностью изолированы, программы из разных контейнеров не могут воздействовать друг на друга.

Контейнеры применяют в распределенных приложениях на инфраструктуре частного или публичного облака,
а также для упаковки устаревших приложений, чтобы упростить их развертывание, в том числе при переносе на другой сервер.

В отличие от виртуальных машин, все контейнеры используют одно и то же ядро операционной системы, которая установлена на сервере.

В этом и недостаток, и преимущество контейнеризации:

  - недостаток — потому что вам недоступен широкий спектр операционных систем и вы не можете обновить ОС в отдельном контейнере;
  - преимущество — потому что отсутствуют накладные расходы на множество отдельных ядер
  и эмуляцию виртуального оборудования. Соответственно, контейнеры потребляют меньше вычислительных ресурсов.

# Slide 5

LXC — система виртуализации на уровне операционной системы для запуска нескольких изолированных экземпляров
операционной системы Linux на одном узле. LXC не использует виртуальные машины, а создаёт виртуальное окружение
с собственным пространством процессов и сетевым стеком.

Контейнер не подходит для изолирования процессов: в системах виртуализации на уровне ядра находят уязвимости,
которые позволяют вылезти из контейнера на хост. Поэтому если вам нужно что-то изолировать, то лучше использовать виртуалку.

Что используется для контейнеризации на уровне ядра

Основные технологии, которые позволяют создавать изолированный от других процессов контейнер, — это Namespaces и Control Groups.

Namespaces: PID, Networking, Mount и User. Есть ещё, но для простоты понимания остановимся на этих.

PID Namespace ограничивает процессы. Когда мы, например, создаём PID Namespace, помещаем туда процесс,
то он становится с PID 1. Обычно в системах PID 1 — это systemd или init. Соответственно, когда мы помещаем процесс
в новый namespace, он тоже получает PID 1.

Networking Namespace позволяет ограничить/изолировать сеть и внутри уже размещать свои интерфейсы. Mount —
это ограничение по файловой системе. User — ограничение по юзерам.

Control Groups: Memory, CPU, IOPS, Network — всего около 12 настроек. Иначе их ещё называют Cgroups («Cи-группы»).

Control Groups управляют ресурсами для контейнера. Через Control Groups мы можем сказать, что контейнер не должен
потреблять больше какого-то количества ресурсов.

Чтобы контейнеризация полноценно работала, используются дополнительные технологии: Capabilities, Copy-on-write и другие.

Capabilities — это когда мы говорим процессу, что он может делать, а чего не может. На уровне ядра это просто битовые
карты со множеством параметров. Например, пользователь root имеет полные привилегии, может делать всё. Сервер времени
может изменять системное время: у него есть capabilities на Time Capsule, и всё. С помощью привилегий можно гибко
настроить ограничения для процессов, и тем самым обезопасить себя.

Когда появились системы виртуализации на уровне ядра, их начали активно применять. Оверхед на гипервизор пропал, но некоторые проблемы остались:
- большие образы: в ту же OpenVZ толкают операционку, библиотеки, кучу разного софта, и в итоге образ всё равно получается немаленьким;
- нет нормального стандарта упаковки и доставки, поэтому остаётся проблема зависимостей. Бывают ситуации,
когда два куска кода используют одну библиотеку, но с разными версиями. Между ними возможен конфликт.

# Slide 6

Pets — это домашние животные. В монолитной эре мы относились к своим серверам, как к домашним животным,
холили и лелеяли, пылинки сдували. А для лучшего управления ресурсами использовали виртуализацию:
брали сервер и пилили на несколько виртуальных машин, тем самым обеспечивая изоляцию окружения.

Новая эра контейнеров.
- Один процесс — один контейнер.
- Все нужные процессу зависимости доставляем в его контейнер. Это требует распиливать монолиты на микросервисы.
- Чем меньше образ, тем лучше — меньше возможных уязвимостей, быстрее раскатывается и так далее.
- Инстансы становятся эфемерными.

Раньше инстансы были подобны домашним животным, а теперь стали как cattle — скот. Раньше был монолит — одно приложение.
Теперь это 100 микросервисов, 100 контейнеров. У каких-то контейнеров может быть по 2-3 реплики.
Нам становится не столь важно контролировать каждый контейнер. Нам скорее важна доступность самого сервиса:
того, что делает этот набор контейнеров. Это меняет подходы в мониторинге.

# Slide 7

Посмотрим на Docker поближе
- Docker daemon (демон) — это серверная часть, она работает на хост-машине: скачивает образы и запускает из них контейнеры,
создаёт сеть между контейнерами, собирает логи. Когда мы говорим «создай образ», этим тоже занимается демон.
- Docker CLI — клиентская часть Docker, консольная утилита для работы с демоном. Повторю, она может работать не только локально, но и по сети.
- Dockerfile — инструкция для создания образа. Почти каждая команда инструкции — новый слой.
- Image — это упаковка контейнера, из образа запускаются контейнеры. Если смотреть на Docker с точки зрения пакетного
менеджера (как будто мы работаем с deb или rpm-пакетами), то image — это по сути rpm-пакет. Через yum install мы можем
поставить приложение, удалить его, найти в репозитории, скачать. Здесь примерно то же самое: из образа запускаются
контейнеры, они хранятся в Docker registry (по аналогии с yum, в репозитории), и каждый image имеет хеш SHA-256, имя и тег.
Image собирается по инструкции из Dockerfile. Каждая инструкция из Dockerfile создаёт новый слой. Слои могут использоваться повторно.
- Docker registry — это репозиторий образов Docker. По аналогии с ОС, у Docker есть общедоступный стандартный реестр —
dockerhub. Но можно собрать свой репозиторий, свой Docker registry.
- Container — то, что запускается из образа. По инструкции из Dockerfile собрали образ, затем мы его из этого образа запускаем.
Этот контейнер изолирован от остальных контейнеров, он должен содержать в себе всё необходимое для работы приложения.
При этом один контейнер — один процесс. Случается, что приходится делать два процесса, но это несколько противоречит идеологии Docker.
Требование «один контейнер — один процесс» связано с PID Namespace. Когда в Namespace запускается процесс с PID 1,
если он вдруг умрёт, то весь контейнер тоже умирает. Если же там запущено два процесса: один живёт, а второй умер,
то контейнер всё равно продолжит жить. Но это к вопросу Best Practices, мы про них поговорим в других материалах.

# Slide 8

Основные команды
Стоит обратить внимание, что можно использовать не только имя, но и хэш контейнера.
Также поддерживаются выражения из bash


# Slide 11

Соберем простое приложение на основе CRA
- подготавливаем проект
- добавляем Dockerfile
- собираем образ
- запускаем контейнер
- пробрасываем папку внутрь контейнера

# Slide 12

docker-compose позволяет
- упростить работу как с одним микросервисом, так и с несколькими
- наладить взаимодействие между ними
- определить записимости (но проверять, запустился ли сервис, придется самому)
- запускать все одной командой, не мучаясь с настройкой бекенда, брокеров сообщений, бд и т.п.

# Slide 13

пробросить переменные окружения в контейнер можно несколькими способами
- в докерфайле
- через ключ/файл при запуске контейнера - можно имя со значением или имя из хост-системы, если оно там определено
- через описание/ссылку на env файл в файле docker-compose


  The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg <varname>=<value> flag.
  The ENV instruction sets the environment variable <key> to the value <value>.
  The environment variables set using ENV will persist when a container is run from the resulting image.


# Slide 14

Том — это файловая система, которая расположена на хост-машине за пределами контейнеров. Созданием и управлением томами занимается Docker. Вот основные свойства томов Docker:

- Они представляют собой средства для постоянного хранения информации.
- Они самостоятельны и отделены от контейнеров.
- Ими могут совместно пользоваться разные контейнеры.
- Они позволяют организовать эффективное чтение и запись данных.
- Тома можно размещать на ресурсах удалённого облачного провайдера.
- Их можно шифровать.
- Им можно давать имена.
- Контейнер может организовать заблаговременное наполнение тома данными.
- Они удобны для тестирования.

Мы посмотрели на несколько способов, как хранить данные в Docker контейнерах: примонтированные папки, тома с данными и тома-контейнеры. Все три официально поддерживаются, и даже встречаются примеры. Но обычные монтированные папки работают только на локальных хостах и не контролируются докером, тома-контейнеры просто похожи на коллекции именованных томов, и только тома с данными выглядят как «трушный» способ управлять данными. Они идут с понятным API, управляются Докером, могут работать как локально, так и удалённо. В общем, умеют всё, что нужно.


# Slide 15

docker-compose
Пример приложения с фронтом и бекендом с апи на экспрессе
Из чего состоит
как пробрасываются env
как запускать/останавливать
дополнительные параметры в описании

# Slide 16

оптимизация контейнеров, как сделать их легкими, рассказать по каждому пункту

# Slide 17

multi-stage сборка из нескольких контейнеров


# Slide 24

Оркестровка — это управление и координация взаимодействия между контейнерами. Контейнеры запускаются на хостах, а хосты объединяют в кластер.

### Docker swarm

Обычно для этого создают кластер — отдельностоящие хосты (серверы) объединяют под общим управлением, со стороны это выглядит как единая система. При этом она намного устойчивее к сбоям и производительнее:

- Отказоустойчивость достигается благодаря избыточности хостов (в рамках кластера они называются нодами). Система работает сразу на нескольких нодах, если одна из них выйдет из строя, остальные спокойно продолжат работу.
- Балансировка нагрузки позволяет равномерно нагрузить каждую ноду. Кластер следит за нагрузкой и сам распределяет внутри себя задачи: одну программу запустит на одной ноде, другую программу — на другой.
- Масштабируемость помогает подстраивать производительность кластера под нагрузку. Если приложениям и сервисам не хватает ресурсов, можно быстро подключить дополнительные ноды.

В Docker Swarm вместо прямого использования контейнеров используются сервисы (Docker Swarm Service). Они похожи на контейнеры, но всё же это немного другое понятие.

Сервис — это что-то вроде уровня абстракции над контейнерами. В Swarm мы не запускаем контейнеры явно — этим занимаются сервисы. Для достижения отказоустойчивости мы лишь указываем сервису количество реплик — нод, на которых он должен запустить контейнеры. А Swarm уже сам проследит за тем, чтобы это требование выполнялось: найдет подходящие хосты, запустит контейнеры и будет следить за ними. Если один из хостов отвалится — создаст новую реплику на другом хосте.

### Kubernetes

Если смотреть глобально, то устройство Kubernetes похоже на Swarm. Кластер состоит из двух типов нод: главной (Master) и рабочих (Worker):

    Master-нода следит за состоянием своего кластера, распределяет нагрузку и разворачивает контейнеры на нодах.
    Рабочие ноды обрабатывают поступающие запросы.

Но если смотреть глубже, то устройство Kubernetes гораздо сложнее. В нем отдельные модули, например: proxy-балансировщик, etcd для хранения состояния кластера и другие компоненты. Не будем подробно всё это описывать. Достаточно понять, что Kubernetes устроен гораздо сложнее, чем Docker Swarm.

Kubernetes позволяет решать задачи, которые не под силу Docker Swarm. Для примера возьмем автомасштабирование: это когда система сама подстраивает свою мощность под нагрузку. Для этого в кластер автоматически добавляются/удаляются ноды, либо в существующих нодах для «тяжелых» задач будет выделяться больше/меньше ресурсов.

Kubernetes можно настроить автомасштабирование. Да, придется написать конфигурационный файл и выполнить другие настройки, но в результате вы получите рабочую и стабильную систему. А если развернуть кластер в облаке, которое поддерживает автомасштабирование, то на настройку уйдет всего несколько минут.

Docker Swarm не умеет делать этого «из коробки». Можно построить автомасштабируемую систему с использованием Swarm. Но для этого придется вручную писать скрипты или программы, которые будут следить за нагрузкой, принимать решения и посылать команды в Docker Swarm. Либо можно использовать сторонние разработки, вроде Orbiter, но его возможности тоже ограничены, и в любом случае это еще одна дополнительная надстройка над Swarm.


# Slide 27

Безопасность контейнеров

В Docker уже встроено несколько замечательных средств обеспечения безопасности:

- Docker-контейнеры минимальны: один или несколько работающих процессов, только необходимое программное обеспечение. Это снижает вероятность пострадать от уязвимостей в ПО.

- Docker-контейнеры выполняют специфическую задачу. Заранее известно, что должно выполняться в контейнере, определены пути к директориям, открытые порты, конфигурации демонов, точки монтирования и т. д. В таких условиях проще обнаружить какие-либо связанные с безопасностью аномалии. Этот принцип организации систем идет рука об руку с микросервисной архитектурой, позволяя значительно уменьшить поверхность атаки.

- Docker-контейнеры изолированы как от хоста, так и от других контейнеров. Этого удается добиться благодаря способности ядра Linux изолировать ресурсы с помощью cgroups и namespaces. Но есть серьезная проблема — ядро приходится делить между хостом и контейнерами (мы еще вернемся к этой теме чуть позже).

- Docker-контейнеры воспроизводимы. Благодаря их декларативной системе сборки любой администратор может легко выяснить, из чего и как был сделан контейнер. Крайне маловероятно, что у вас в итоге окажется неизвестно кем настроенная legacy-система, которую никому не хочется конфигурировать заново. Знакомо, не правда ли? ;)

### безопасность хоста

Лучшие практики

Тема обеспечения безопасности Linux-хоста весьма обширна, и по ней написано немало литературы. Что касается исключительно Docker:

- Убедитесь в безопасности конфигурации хоста и Docker engine (доступ ограничен и предоставлен только аутентифицированным пользователям, канал связи зашифрован и т. д.) Для проверки конфигурации на соответствие лучшим практикам рекомендую воспользоваться инструментом Docker bench audit tool.

- Своевременно обновляйте систему, подпишитесь на рассылку по безопасности операционной системы и другого установленного программного обеспечения, особенно если оно устанавливается из сторонних репозиториев (например, системы оркестровки контейнеров, одну из которых вы уже наверняка установили).

- Используйте минимальные, специально предназначенные для использования с контейнерами хост-системы, такие как CoreOS, Red Hat Atomic, RancherOS и т. д. Это позволит уменьшить поверхность атаки, а также воспользоваться такими удобными функциями, как, например, выполнение системных сервисов в контейнерах.

- Для предотвращения выполнения нежелательных операций как на хосте, так и в контейнерах можно задействовать систему Мандатного управления доступом (Mandatory Access Control). В этом вам помогут такие инструменты, как Seccomp, AppArmor или SELinux.

### Выход за пределы Docker-контейнера

Термин «выход за пределы контейнера» (container breakout) используется для обозначения ситуации, при которой какой-либо программе, запущенной внутри Docker-контейнера, удается преодолеть механизмы изоляции и получить дополнительные привилегии или доступ к конфиденциальной информации на хосте. Для предотвращения подобных прорывов используется уменьшение количества привилегий контейнера, выдаваемых ему по умолчанию. Например, демон Docker по умолчанию выполняется под рутом, однако существует возможность создать пользовательское пространство имен (user-level namespace) или снять потенциально опасные привилегии контейнера.

- Привилегии (capabilities), которые не нужны приложению, должны быть сняты.

- Чтобы привилегии контейнера были эквиваленты правам обычного пользователя, создайте для ваших контейнеров изолированное пользовательское пространство имен. По возможности избегайте выполнения контейнеров с uid 0.

- Если без привилегированного контейнера все же не обойтись, убедитесь, что он устанавливается из доверенного репозитория (см. ниже раздел «Подлинность образов контейнеров»).

- Внимательно следите за случаями монтирования потенциально опасных ресурсов хоста: /var/run/docker.sock), /proc, /dev и т. д. Обычно эти ресурсы нужны для выполнения операций, связанных с базовой функциональностью контейнеров. Убедитесь, что вы понимаете, почему и как необходимо ограничивать доступ процессов к этой информации. Иногда достаточно лишь установки режима «только чтение». Никогда не давайте права на запись, не задавшись вопросом, зачем нужно это право. В любом случае Docker использует copy-on-write, чтобы предотвратить попадание изменений, произошедших в выполняющемся контейнере, в его базовый образ и потенциально в другие контейнеры, которые будут созданы на базе этого образа.

### Подлинность образов Docker

- Обычный здравый смысл: не запускайте непроверенное ПО и/или ПО, полученное из недоверенных источников.

- С помощью серверов реестров Docker, которые можно найти в этом списке Docker Security Tools, разверните доверенный сервер (trust server).

- Для любого образа, который загружается или запускается в системе, обеспечьте обязательную проверку цифровой подписи.

### Злоупотребление ресурсами


По умолчанию в большинстве систем контейнеризации ограничение этих ресурсов отключено. Однако в production их настройка просто обязательна. Рекомендую придерживаться следующих принципов:

- Используйте функции ограничения ресурсов, идущие в составе ядра Linux и/или системы контейнеризации.

- Постарайтесь провести нагрузочное тестирование системы перед ее запуском в промышленную эксплуатацию. Для этого используются как синтетические тесты, так и «проигрывание» реального трафика боевой системы. Нагрузочное тестирование жизненно важно для выяснения предельных и нормальных рабочих нагрузок.

- Разверните систему мониторинга и оповещения для Docker. Уверен, что в случае злоупотребления ресурсами (злонамеренного или нет) вы предпочтете получить своевременное предупреждение, вместо того чтобы вре́заться в стену на полном ходу.

### Уязвимости в образах контейнеров


Представление контейнеров в виде неизменяемых атомарных частей системы обоснованно с архитектурной точки зрения, однако для обеспечения безопасности их содержимое нужно регулярно проверять:

- Чтобы получить свежие исправления уязвимостей, регулярно обновляйте и пересобирайте свои образы. Разумеется, не забывайте тестировать их перед тем, как отправлять в production.
  - Патчить работающие контейнеры считается дурным тоном. Лучше при каждом обновлении пересобирать образ. В Docker реализована декларативная, эффективная и легкая для понимания система сборки, так что эта процедура на самом деле проще, чем кажется на первый взгляд.
  - Используйте программное обеспечение, которое регулярно получает обновления безопасности. Все, что вы устанавливаете вручную, минуя репозитории вашего дистрибутива, необходимо в дальнейшем обновлять самостоятельно.
  - Постепенные роллинг-обновления без прерывания работы сервиса считаются фундаментальным свойством модели построения систем с помощью Docker и микросервисов.
  - Пользовательские данные отделены от образов контейнеров, что делает процесс обновления безопаснее.
- Не усложняйте. Простые системы реже требуют обновлений. Чем меньше компонентов в системе, тем меньше поверхность атаки и проще обновления. Разбивайте контейнеры, если они становятся слишком сложными.
- Используйте сканеры уязвимостей. Их сейчас предостаточно — и бесплатных, и коммерческих. Старайтесь быть в курсе событий, связанных с безопасностью используемого вами программного обеспечения, подпишитесь на почтовые рассылки, сервисы оповещений и т. д.
- Сделайте сканирование безопасности обязательным этапом своей CI/CD-цепочки, автоматизируйте по возможности — не стоит полагаться лишь на ручные проверки.

### Учетные данные и секреты Docker

- Не используйте переменные окружения для хранения секретов. Это распространенная и небезопасная практика.

- Не сохраняйте секреты в образах контейнеров. Прочитайте этот отчет о нахождении и устранении уязвимости в одном из сервисов IBM: «Закрытый ключ и сертификат были по ошибке оставлены внутри образа контейнера».

- Если у вас достаточно сложная система, разверните программное обеспечение управления учетными данными Docker. В статье Docker security tools мы рассмотрели несколько коммерческих и бесплатных решений. Беритесь за создание собственного хранилища секретов (с загрузкой секретов с помощью curl, монтированием томов и т. д. и т. п.) только в том случае, если вы очень хорошо знаете, что делаете.

### Мониторинг безопасности Docker во время выполнения

- Вышеописанные статические контрмеры не покрывают все возможные векторы атаки. А что если в вашем собственном приложении есть уязвимости или атакующие используют 0-day, который не определяется сканером? Безопасность времени выполнения можно сравнить с антивирусным сканированием в Windows, в задачи которого входит нахождение вредоносных программ и предотвращение дальнейшего распространения атаки.

- Не нужно заменять статическую проверку образов на динамическую защиту времени выполнения, поскольку предотвращение атаки всегда лучше ее отражения. Используйте динамическую защиту в качестве дополнительного уровня безопасности.

- Для посмертного анализа атаки очень помогают подробные и удобные логи, содержимое которых хорошо коррелирует с внесенными в систему изменениями.


# Источники:
- https://habr.com/ru/company/southbridge/blog/515508/
- https://habr.com/ru/company/selectel/blog/279281/
- https://habr.com/ru/company/selectel/blog/303190/

env:
- https://vsupalov.com/docker-build-time-env-values/
- https://vsupalov.com/docker-arg-env-variable-guide/

работа с данными
- https://habr.com/ru/company/ruvds/blog/441574/
- https://dotsandbrackets.com/persistent-data-docker-volumes-ru/

оптимизация
- https://habr.com/ru/post/234829/
- https://docs.docker.com/develop/develop-images/dockerfile_best-practices/

тестирование
- https://tproger.ru/translations/testing-and-debugging-a-containerized-node-application/

деплой
- https://habr.com/ru/post/466493/

логирование / мониторинг
- https://linux-notes.org/rabota-s-logami-logs-v-docker/
- https://www.youtube.com/watch?v=bWJhh4gQppA
- [логирование и мониторинг с прометеем](https://ealebed.github.io/posts/2017/%D0%BC%D0%BE%D0%BD%D0%B8%D1%82%D0%BE%D1%80%D0%B8%D0%BD%D0%B3-docker-c-%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E-prometheus/)
- [драйвер логов](https://zyatev.ru/devops/chto-nuzhno-znat-o-logirovanii-v-docker-pered-zapuskom-proekta-v-prodakshen)


оркестрация
- https://www.xelent.ru/blog/chto-takoe-orkestratsiya-konteynerov/
- https://mcs.mail.ru/blog/docker-swarm-ili-kubernetes-chto-luchshe
- https://zen.yandex.ru/media/merion_networks/14-instrumentov-orkestracii-konteinerov-dlia-devops-5f48b355c73efb28a6dca8ff

безопасность
- https://habr.com/ru/company/southbridge/blog/339126/